{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import word2vec, CoherenceModel\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans\n",
    "import hdbscan\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import clean\n",
    "import word_2dviz\n",
    "import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from CSV\n",
    "df = pd.read_csv(\"nightwish_lyrics.csv\")\n",
    "\n",
    "# Drop rows that no longer have lyrics\n",
    "df_clean = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate lyrics by song\n",
    "df_song = (\n",
    "    df_clean.groupby([\"track_title\"])[\"lyric_lemma\"]\n",
    "    .apply(lambda x: \" \".join(x))\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  JOIN df_song with df_clean for album title and year\n",
    "df_merged = df_song.merge(\n",
    "    df_clean[[\"track_title\", \"album_title\", \"year\"]],\n",
    "    on=\"track_title\",\n",
    "    validate=\"one_to_many\",\n",
    ")\n",
    "\n",
    "# Drop duplicated rows\n",
    "df_merged.drop_duplicates(inplace=True)\n",
    "\n",
    "# Reset index\n",
    "df_merged.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of studio albumns by Nightwish\n",
    "studio_albums = [\n",
    "    \"Angels Fall First\",\n",
    "    \"Oceanborn\",\n",
    "    \"Wishmaster\",\n",
    "    \"Century Child\",\n",
    "    \"Once\",\n",
    "    \"Dark Passion Play\",\n",
    "    \"Imaginaerum\",\n",
    "    \"Hvman. :||: Natvre.\",\n",
    "]\n",
    "\n",
    "# Only keep in-album songs\n",
    "df_merged = df_merged.loc[df_merged[\"album_title\"].isin(studio_albums)]\n",
    "\n",
    "# Reset index\n",
    "df_merged.reset_index(inplace=True)\n",
    "\n",
    "# Drop extra columns\n",
    "df_merged.drop([\"level_0\", \"index\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually filter out more stopwords\n",
    "filter = [\"s\", \"oh\", \"ah\", \"o\", \"e\", \"ee\", \"ieee\", \"let\"]\n",
    "\n",
    "lyrics_clean = []\n",
    "\n",
    "for lyric in df_merged[\"lyric_lemma\"]:\n",
    "    lyric_list_clean = [word for word in lyric.split() if word not in filter]\n",
    "    lyric_clean = \" \".join(lyric_list_clean)\n",
    "    lyrics_clean.append(lyric_clean)\n",
    "\n",
    "df_merged[\"lyric_lemma\"] = lyrics_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words\n",
    "lyrics = df_merged[\"lyric_lemma\"].tolist()\n",
    "lyrics = [i for i in lyrics if i]  # Remove empty strings\n",
    "tokens = [lyric.split() for lyric in lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty lists\n",
    "tokens = [i for i in tokens if i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"bag of words\"\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "dictionary.filter_extremes(\n",
    "    no_below=10, no_above=0.5\n",
    ")  # Filter out words that are too rare or too common\n",
    "corpus_bow = [dictionary.doc2bow(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF\n",
    "tfidf = models.TfidfModel(corpus_bow)\n",
    "corpus_tfidf = tfidf[corpus_bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "ldamodel_bow = LdaModel(corpus_bow, id2word=dictionary, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find topics across songs\n",
    "def lda_model(n_topic, corpus):\n",
    "\n",
    "    # Run LDA\n",
    "    ldamodel = gensim.models.LdaMulticore(\n",
    "        corpus, num_topics=n_topic, id2word=dictionary, passes=10\n",
    "    )\n",
    "\n",
    "    # Show topics\n",
    "    for idx, topic in ldamodel.print_topics(-1):\n",
    "        print(f\"Topic: {idx} \\nWords: {topic} \\n\")\n",
    "\n",
    "    # Return model\n",
    "    return ldamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.043*\"away\" + 0.037*\"night\" + 0.036*\"dream\" + 0.029*\"come\" + 0.027*\"world\" + 0.025*\"tale\" + 0.023*\"star\" + 0.022*\"want\" + 0.022*\"earth\" + 0.021*\"sing\" \n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.057*\"come\" + 0.039*\"wish\" + 0.039*\"rest\" + 0.034*\"dream\" + 0.033*\"night\" + 0.029*\"home\" + 0.026*\"deep\" + 0.026*\"day\" + 0.023*\"angel\" + 0.023*\"face\" \n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.058*\"heart\" + 0.042*\"world\" + 0.040*\"die\" + 0.032*\"dead\" + 0.030*\"lie\" + 0.030*\"heaven\" + 0.028*\"soul\" + 0.026*\"great\" + 0.026*\"time\" + 0.024*\"man\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ldamodel_bow2 = lda_model(3, corpus_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominant_topic(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(\n",
    "                    pd.Series([int(topic_num), round(prop_topic, 4), topic_keywords]),\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = [\"Dominant_Topic\", \"Perc_Contribution\", \"Topic_Keywords\"]\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return sent_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>dream, heart, wish, world, child, night, come,...</td>\n",
       "      <td>[wolf, love, come, take, home, dust, man, life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>soul, sea, night, die, come, world, wish, hear...</td>\n",
       "      <td>[star, fall, darken, sky, new, world, bear, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>come, night, heart, dream, away, world, beauty...</td>\n",
       "      <td>[look, dot, home, love, know, hear, human, liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>come, night, heart, dream, away, world, beauty...</td>\n",
       "      <td>[baptise, perfect, doubt, heart, war, day, nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>come, night, heart, dream, away, world, beauty...</td>\n",
       "      <td>[angel, face, smile, headline, tragedy, smile,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>come, night, heart, dream, away, world, beauty...</td>\n",
       "      <td>[want, siren, sing, hear, wolf, howl, sail, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>come, night, heart, dream, away, world, beauty...</td>\n",
       "      <td>[enchantress, come, say, meet, lake, tonight, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>come, night, heart, dream, away, world, beauty...</td>\n",
       "      <td>[seduce, dark, pain, rapture, like, ship, pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>dream, heart, wish, world, child, night, come,...</td>\n",
       "      <td>[deep, die, day, take, step, outside, innocent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4196</td>\n",
       "      <td>dream, heart, wish, world, child, night, come,...</td>\n",
       "      <td>[master, apprentice, heartburn, th, seeker, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic  Perc_Contribution  \\\n",
       "0              0.0             0.7063   \n",
       "1              1.0             0.9533   \n",
       "2              2.0             0.9741   \n",
       "3              2.0             0.9852   \n",
       "4              2.0             0.9632   \n",
       "..             ...                ...   \n",
       "86             2.0             0.9737   \n",
       "87             2.0             0.5878   \n",
       "88             2.0             0.9647   \n",
       "89             0.0             0.9847   \n",
       "90             0.0             0.4196   \n",
       "\n",
       "                                       Topic_Keywords  \\\n",
       "0   dream, heart, wish, world, child, night, come,...   \n",
       "1   soul, sea, night, die, come, world, wish, hear...   \n",
       "2   come, night, heart, dream, away, world, beauty...   \n",
       "3   come, night, heart, dream, away, world, beauty...   \n",
       "4   come, night, heart, dream, away, world, beauty...   \n",
       "..                                                ...   \n",
       "86  come, night, heart, dream, away, world, beauty...   \n",
       "87  come, night, heart, dream, away, world, beauty...   \n",
       "88  come, night, heart, dream, away, world, beauty...   \n",
       "89  dream, heart, wish, world, child, night, come,...   \n",
       "90  dream, heart, wish, world, child, night, come,...   \n",
       "\n",
       "                                                    0  \n",
       "0   [wolf, love, come, take, home, dust, man, life...  \n",
       "1   [star, fall, darken, sky, new, world, bear, di...  \n",
       "2   [look, dot, home, love, know, hear, human, liv...  \n",
       "3   [baptise, perfect, doubt, heart, war, day, nee...  \n",
       "4   [angel, face, smile, headline, tragedy, smile,...  \n",
       "..                                                ...  \n",
       "86  [want, siren, sing, hear, wolf, howl, sail, de...  \n",
       "87  [enchantress, come, say, meet, lake, tonight, ...  \n",
       "88  [seduce, dark, pain, rapture, like, ship, pass...  \n",
       "89  [deep, die, day, take, step, outside, innocent...  \n",
       "90  [master, apprentice, heartburn, th, seeker, wa...  \n",
       "\n",
       "[91 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dominant_topic(ldamodel_bow, corpus_bow, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8336</td>\n",
       "      <td>come, wish, rest, dream, night, home, deep, da...</td>\n",
       "      <td>[wolf, love, come, take, home, dust, man, life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>heart, world, die, dead, lie, heaven, soul, gr...</td>\n",
       "      <td>[star, fall, darken, sky, new, world, bear, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>come, wish, rest, dream, night, home, deep, da...</td>\n",
       "      <td>[look, dot, home, love, know, hear, human, liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>heart, world, die, dead, lie, heaven, soul, gr...</td>\n",
       "      <td>[baptise, perfect, doubt, heart, war, day, nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>come, wish, rest, dream, night, home, deep, da...</td>\n",
       "      <td>[angel, face, smile, headline, tragedy, smile,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7187</td>\n",
       "      <td>away, night, dream, come, world, tale, star, w...</td>\n",
       "      <td>[want, siren, sing, hear, wolf, howl, sail, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>come, wish, rest, dream, night, home, deep, da...</td>\n",
       "      <td>[enchantress, come, say, meet, lake, tonight, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>come, wish, rest, dream, night, home, deep, da...</td>\n",
       "      <td>[seduce, dark, pain, rapture, like, ship, pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>come, wish, rest, dream, night, home, deep, da...</td>\n",
       "      <td>[deep, die, day, take, step, outside, innocent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6896</td>\n",
       "      <td>away, night, dream, come, world, tale, star, w...</td>\n",
       "      <td>[master, apprentice, heartburn, th, seeker, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic  Perc_Contribution  \\\n",
       "0              1.0             0.8336   \n",
       "1              2.0             0.8578   \n",
       "2              1.0             0.8149   \n",
       "3              2.0             0.9857   \n",
       "4              1.0             0.6334   \n",
       "..             ...                ...   \n",
       "86             0.0             0.7187   \n",
       "87             1.0             0.9591   \n",
       "88             1.0             0.7478   \n",
       "89             1.0             0.9845   \n",
       "90             0.0             0.6896   \n",
       "\n",
       "                                       Topic_Keywords  \\\n",
       "0   come, wish, rest, dream, night, home, deep, da...   \n",
       "1   heart, world, die, dead, lie, heaven, soul, gr...   \n",
       "2   come, wish, rest, dream, night, home, deep, da...   \n",
       "3   heart, world, die, dead, lie, heaven, soul, gr...   \n",
       "4   come, wish, rest, dream, night, home, deep, da...   \n",
       "..                                                ...   \n",
       "86  away, night, dream, come, world, tale, star, w...   \n",
       "87  come, wish, rest, dream, night, home, deep, da...   \n",
       "88  come, wish, rest, dream, night, home, deep, da...   \n",
       "89  come, wish, rest, dream, night, home, deep, da...   \n",
       "90  away, night, dream, come, world, tale, star, w...   \n",
       "\n",
       "                                                    0  \n",
       "0   [wolf, love, come, take, home, dust, man, life...  \n",
       "1   [star, fall, darken, sky, new, world, bear, di...  \n",
       "2   [look, dot, home, love, know, hear, human, liv...  \n",
       "3   [baptise, perfect, doubt, heart, war, day, nee...  \n",
       "4   [angel, face, smile, headline, tragedy, smile,...  \n",
       "..                                                ...  \n",
       "86  [want, siren, sing, hear, wolf, howl, sail, de...  \n",
       "87  [enchantress, come, say, meet, lake, tonight, ...  \n",
       "88  [seduce, dark, pain, rapture, like, ship, pass...  \n",
       "89  [deep, die, day, take, step, outside, innocent...  \n",
       "90  [master, apprentice, heartburn, th, seeker, wa...  \n",
       "\n",
       "[91 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dominant_topic(ldamodel_bow2, corpus_bow, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
